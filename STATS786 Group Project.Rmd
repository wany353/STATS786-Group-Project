---
title: "STATS 786 Group Project"
author: "Yucheng Wang, Eric Shi, Tongxin Li, Jinze Li"
date: "2024-05-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(fpp3)
library(tsibbledata)
library(kableExtra)
library(gt)
library(urca)
Sys.setlocale("LC_TIME", "English_United States.1252")

surrogate.test = function(data, lag, N = 1000, test.stat = "ljung-box") {
  
  # data: a tsibble or numeric vector object
  # lag: number of lags in portmanteau test statistic
  # N: number of permutations to perform
  # test.stat: either "ljung-box" or "box-pierce"
  
  if (is_tsibble(data)) {
    if (length(measures(data)) != 1) {  
      stop("data must be a tsibble with one measurement variable")
    }
    # Extract time series 
    data = data %>% 
      pull(as.character(measures(data)[[1]])) 
  }

  n = length(data)

  Q.null = rep(NA, N)  # Open test statistic vectors
  
  if (test.stat == "ljung-box") {
    
    # Observed test statistic
    r.obs = acf(data, plot = FALSE)$acf[2:(lag + 1)]
    Q.obs = n * (n + 2) * sum(r.obs ^ 2 / (n - 1:lag))
    
    # Null distribution
    for (i in 1:N) {
      surrogate = sample(data, n)  # Permute data (kill autocorrelation, maintain amplitude)
      r = acf(surrogate, plot = FALSE)$acf[2:(lag + 1)]   # Estimate autocorrelation
      Q.null[i] = n * (n + 2) * sum(r ^ 2 / (n - 1:lag))  # Ljung-Box test statistic
    }
    
  }
  
  if (test.stat == "box-pierce") {
    
    # Observed test statistic
    r.obs = acf(data, plot = FALSE)$acf[2:(lag + 1)]
    Q.obs = n * sum(r.obs ^ 2)
    
    # Null distribution
    for (i in 1:N) {
      surrogate = sample(data, n)  # Permute data (kill autocorrelation, maintain amplitude)
      r = acf(surrogate, plot = FALSE)$acf[2:(lag + 1)]  # Estimate autocorrelation
      Q.null[i] = n * sum(r ^ 2)                         # Box-Pierce test statistic
    }
    
  }
  
  # Compute p-value
  p.value = mean(Q.null >= Q.obs)  # p-value

  # Output
  output = list(Q.null = Q.null,
                Q.obs = Q.obs,
                test.stat = test.stat,
                p.value = p.value)
  
  class(output) = "surrogate"
  
  return(output)
  
}

plot.surrogate = function(obj) {
  
  # obj: Object of class "surrogate"

  ggplot(data = data.frame(Q = obj$Q.null),
         mapping = aes(x = Q)) +
    geom_histogram(fill = "navy", colour = "black") +
    geom_vline(xintercept = obj$Q.obs,
               linetype = "dashed") +
    labs(x = "Test statistic",
         y = "Count") 
  
}
```

# 1. Exploratory data analysis

```{r, warning=FALSE}
# read in the data
train <- read_csv('qgdp_training.csv') %>%
  mutate(Date = yearquarter(Date)) %>%
  as_tsibble(index = Date) %>% 
  select(1, 17)

full <- read_csv("qgdp_full.csv") %>%
  mutate(Date = yearquarter(Date)) %>%
  as_tsibble(index = Date) %>% 
  select(1, 17)


train %>% 
  autoplot()
# STL component plot
train %>%
  model(stl = STL(`Wholesale Trade`, robust = TRUE)) %>%
  components() %>%
  autoplot()
```

The time plot shows an overall upward trend. It can be observed that the data has obvious periodic fluctuations, reflecting seasonal variations.

For Trend:
From the plot, it can be seen that the wholesale volume shows an overall upward trend. In the early period, the growth was slow. During the middle period (approximately from 2000 to 2010), there was a period of stability, and then in recent years, it began to rise rapidly.

For Seasonal:
The seasonal plot shows periodic fluctuations. In the early period, the seasonal fluctuations were relatively small and stable, but starting from the middle period, the amplitude of the fluctuations increased significantly.

For Remainder:
The remainder part looks relatively random, indicating that after removing the trend and seasonal components, there are no obvious structures or patterns.



# 2. ETS models

```{r}
#ETS model
ets_manual <- train %>%
  model(
    ets_mam = ETS(`Wholesale Trade` ~ error("M") + trend("A") + season("M")),
    ets_aaa = ETS(`Wholesale Trade` ~ error("A") + trend("A") + season("A")),
    ets_ana = ETS(`Wholesale Trade` ~ error("A") + trend("N") + season("A"))
  )


# auto ETS
ets_auto <- train %>%
  model(ets = ETS(`Wholesale Trade`))

report(ets_auto)


glance(ets_manual) %>%
  arrange(AICc)

glance(ets_auto)
```

By comparing the AICc values, we found that the smallest AICc belongs to both
the manually fitted MAM ETS model and the automatically fitted model.
Since they have the same AICc, we can select the best performing model,
which is ets_mam.

# 3. ARIMA models
## Transformations

```{r}
guerrero(train$`Wholesale Trade`)

train %>%
  autoplot(box_cox(`Wholesale Trade`, -0.14))
```

It looks like multiplicative seasonality is present, so a Box-Cox transformation
was applied. Guerrero's method suggested a lambda parameter of -0.14.

## Differencing

```{r}
train %>%
	features(box_cox(`Wholesale Trade`, -0.14), unitroot_kpss)

train %>%
	features(difference(box_cox(`Wholesale Trade`, -0.14), lag=4), unitroot_kpss)
```

Performing the KPSS test on the Box-Cox wholesale trade variable before
differencing gave a p-value of 0.01, so we have strong evidence against
the null hypothesis that the time series is stationary.

A seasonal difference was applied because it looks like seasonality is present.
Performing the KPSS test on the seasonally differenced series gave a p-value
of 0.1, so we can assume the series is stationary and no further differencing
is required.

```{r}
train %>%
  gg_tsdisplay(difference(box_cox(`Wholesale Trade`, -0.14), lag=4), plot_type="partial")

arima_fit = train %>%
  model(auto = ARIMA(box_cox(`Wholesale Trade`, -0.14), stepwise=F, approximation=F),
        arima100210 = ARIMA(box_cox(`Wholesale Trade`, -0.14) ~ pdq(1,0,0) + PDQ(2,1,0)),
        arima100011 = ARIMA(box_cox(`Wholesale Trade`, -0.14) ~ pdq(1,0,0) + PDQ(0,1,1)),
        arima002210 = ARIMA(box_cox(`Wholesale Trade`, -0.14) ~ pdq(0,0,2) + PDQ(2,1,0)),
        arima002011 = ARIMA(box_cox(`Wholesale Trade`, -0.14) ~ pdq(0,0,2) + PDQ(0,1,1)))

glance(arima_fit) %>% arrange(AICc) %>% select(.model:BIC)

arima_fit$auto
```

To come up with candidate models, we used the ARIMA function to find a model
automatically, as well as manually finding models by considering the ACF and
PACF plots.

The PACF plot has spikes at lags 4 and 8, suggesting 2 seasonal AR terms, and
a spike at lag 1, suggesting 1 non-seasonal AR term. The ACF plot has spikes at
lag 4, suggesting 1 seasonal MA term, and spikes at lags 1 and 2, suggesting 2
non-seasonal MA terms. Therefore, we considered models ARIMA(1,0,0)(0,1,1)[4],
ARIMA(1,0,0)(2,1,0)[4], ARIMA(0,0,2)(0,1,1)[4], and ARIMA(0,0,2)(2,1,0)[4].

Overall, the ARIMA model with the best predictive ability is the automatically
found ARIMA(0,0,3)(0,1,1)[4] due to it having the lowest AICc score.

## Fitted model equation

The model equation in backshift notation is 
$$(1-B^4)w_t = (1+\Theta_1B^4)(1+\theta_1B+\theta_2B^2+\theta_3B^3)
\varepsilon_t$$

where $\varepsilon_t \sim N(0, \sigma^2)$ and
$w_t = (sign(y_t)|y_t|^{-0.14}-1)/(-0.14)$.

# 4. Neural network autoregression (NNAR) models

```{r, warning=FALSE}

NNAR_fit <- train %>% 
  model(NNETAR(`Wholesale Trade`))

report(NNAR_fit)

augment(NNAR_fit)

train %>% 
  autoplot(`Wholesale Trade`, color = 'purple', alpha = 0.5) +
  geom_line(aes(y = augment(NNAR_fit)$.fitted))

accuracy(NNAR_fit)


```
Our neural network autoregressive model is NNAR(1,1,2)[4]:
- **NNAR(p,P,k)[m]**: This is the notation for the model, where:
  - `p`: Number of lagged inputs (autoregressive terms). Here, `p=1`.
  - `P`: Number of seasonal lags. Here, `P=1`.
  - `k`: Number of hidden nodes in the hidden layer. Here, `k=2`.
  - `m`: The periodicity of the time series data. Here, `m=4` indicate that it's quarterly data.


The model is an ensemble of 20 neural networks, and the predictions are averaged over these networks. Using multiple networks helps in reducing the variance of the predictions and improving robustness.

Each individual neural network in the ensemble has:
- **2 input nodes**: Corresponding to the lagged inputs and seasonal lags.
- **2 hidden nodes**: In the hidden layer.
- **1 output node**: Providing the forecasted value.

The model has a total of 9 weights, which include the weights connecting the input layer to the hidden layer and the hidden layer to the output layer, plus biases.

The output units of the neural network are linear, meaning the activation function used in the output layer is linear. This is typical for regression problems where the target variable is continuous.

The `sigma^2` (variance of the residuals) is estimated as 13233. This provides an indication of the model's error variance, which is a measure of how much the model's predictions deviate from the actual values.



# 5. Assumption checking

## Explanation of surrogate data testing for independence in time series

Surrogate data testing is a method used to assess the statistical significance of features observed in time series data. It helps determine whether observed characteristics in the data could have occurred by chance under a null hypothesis that assumes the data is independent and identically distributed.

### Random Shuffle Method

- Shuffling: The data is shuffled randomly, destroying any time-dependent structure (like autocorrelation) while preserving other properties such as the mean and variance. This random permutation is repeated many times to generate surrogate datasets.

- Calculation of Test Statistics: For each surrogate dataset, a test statistic is calculated. Commonly used statistics include the Ljung-Box and Box-Pierce test statistics.

- Comparison with Original Data: The test statistic of the original (unshuffled) dataset is compared against the distribution of test statistics obtained from the shuffled (surrogate) datasets. If the original statistic is significantly higher than those from the surrogates, it suggests that the observed autocorrelation is unlikely to have occurred by chance, implying non-independence in the data.

### Ljung-Box and Box-Pierce Tests

- Ljung-Box Test: Calculates a statistic based on the sum of squared autocorrelations, adjusted for sample size and the number of lags considered. It's particularly sensitive to autocorrelations at higher lags.

- Box-Pierce Test: A simpler version of the Ljung-Box test that uses a straightforward sum of squared autocorrelations.

## ETS

```{r}
ets_manual %>% 
  select(ets_mam) %>% 
  gg_tsresiduals()
```

Based on the residual plot, the residuals are distributed around zero with no obvious trends or patterns, indicating that the residuals have a zero mean.

From the ACF plot, all values are within the range, so it can be considered that there is no autocorrelation.

Regarding the distribution, the plot shows a slightly normal distribution, but it can generally be regarded as normal.

The p-value is 0.25, which is greater than 0.05, so we do not have enough evidence to reject the null hypothesis, and therefore we consider the residuals to be white noise.


## 5.4 Code explain:
surrogate.test = function(data, lag, N = 1000, test.stat = "ljung-box") {

The surrogate.test function is used to test the independence of time series data. It accepts the following parameters:
data: A tsibble object or numeric vector representing the data to be tested.
lag: The number of lags to be used in the portmanteau test statistic.
N: The number of permutations to perform, with a default value of 1000.
test.stat: The type of statistical test to be used, which can be either “ljung-box” or “box-pierce”.





if (is_tsibble(data)) {
  if (length(measures(data)) != 1) {
    stop("data must be a tsibble with one measurement variable")
  }
  data = data %>% pull(as.character(measures(data)[[1]]))
}

If the input data is a tsibble object, the function ensures that it has only one measurement variable and then extracts the time series data for that variable.




n = length(data)
Q.null = rep(NA, N)
Initialize some variables, including the data length n and a vector Q.null for storing the permutation statistics.




if (test.stat == "ljung-box") {
  r.obs = acf(data, plot = FALSE)$acf[2:(lag + 1)]
  Q.obs = n * (n + 2) * sum(r.obs ^ 2 / (n - 1:lag))
}
If the “ljung-box” test is used, the function first calculates the autocorrelation function (ACF) of the original data and then computes the Ljung-Box test statistic Q.obs based on it.




if (test.stat == "box-pierce") {
  r.obs = acf(data, plot = FALSE)$acf[2:(lag + 1)]
  Q.obs = n * sum(r.obs ^ 2)
}
If the “box-pierce” test is used, the function computes the Box-Pierce test statistic Q.obs.





for (i in 1:N) {
  surrogate = sample(data, n)
  r = acf(surrogate, plot = FALSE)$acf[2:(lag + 1)]
  if (test.stat == "ljung-box") {
    Q.null[i] = n * (n + 2) * sum(r ^ 2 / (n - 1:lag))
  } else {
    Q.null[i] = n * sum(r ^ 2)
  }
}
Generate surrogate data and compute the surrogate statistics. By randomly shuffling the original data, generate N surrogate datasets and compute the statistic Q.null for each surrogate dataset.






p.value = mean(Q.null >= Q.obs)
output = list(Q.null = Q.null, Q.obs = Q.obs, test.stat = test.stat, p.value = p.value)
class(output) = "surrogate"
return(output)
By comparing the surrogate statistics with the original statistic, compute the p-value. The p-value is the proportion of surrogate statistics that are greater than or equal to the original statistic. Finally, return the results as a list.






ETS=ets_manual %>% select(ets_mam)
ETS.resid <- ETS %>% augment() %>% select(.innov)
Select the residual data from the model and store it in ETS.resid.





p_value <- surrogate.test(ETS.resid$.innov, 8, 1000)$p.value
print(p_value)

Use the surrogate.test function to test the independence of the residuals, with a lag period of 8 and 1000 permutations. Finally, output the p-value.




```{r}
ETS=ets_manual %>% 
  select(ets_mam)

ETS.resid <- ETS %>%
  augment() %>%
  select(.innov)

p_value <- surrogate.test(ETS.resid$.innov, 8, 1000)$p.value

print(p_value)
```

A p-value of 0.815 indicates that we do not have enough evidence to reject the hypothesis of independence of the residuals. This means that, from a statistical perspective, the residuals appear to be independent.

## ARIMA

```{r}
set.seed(0)

arima_fit %>%
  select(auto) %>%
  gg_tsresiduals()

ARIMA.resid = augment(arima_fit) %>%
  filter(.model == "auto") %>%
  select(.innov)

surrogate.test(ARIMA.resid, 8, 1000)$p.value
```

The surrogate test p-value of 0.998 suggests that the residuals are consistent
with white noise.

## NNAR

```{r}
#Extract the residuals from the model fit.
residuals <- NNAR_fit %>%
  augment() %>%
  select(.innov)

#Remove any NA values from the residuals. This is because any missing values may affect the results of the independence test.
residuals_clean <- na.omit(residuals)

#Independence tests are performed using the cleaned residuals. surrogate.test function scrambles the residual data several times (default 1000 times), calculates and records a residual-based Ljung-Box or Box-Pierce statistic each time, and then compares the distribution of the statistic from the original data to the statistic produced by scrambling the data in order to calculate the p value.
s <- surrogate.test(residuals_clean$.innov, 8, 1000)

#Outputs the p-value
print(s$p.value)
```

The surrogate test p-value of 0.018， which means there is a degree of autocorrelation in the residuals.

# 6. Forecasting

## ETS

```{r}
ETS=ets_manual %>% 
  select(ets_mam)

# forecast
forecasts <- ETS %>%
  forecast(h = "2 years") 

# forecast plot
#autoplot(forecasts) +
#  labs(title = "ETS Model Forecast",
#       y = "Wholesale Trade",
#       x = "Time")

autoplot(forecasts) +
  autolayer(full) + 
  labs(title = "ETS Model Forecast",
       y = "Wholesale Trade",
       x = "Time") +
  theme_minimal()

hilo(forecasts, 95)
```

## ARIMA

```{r}
arima_fc = arima_fit %>% select(auto) %>% forecast(h=8)
hilo(arima_fc, 95)

autoplot(arima_fc) +
  autolayer(full) + 
  labs(title = "ARIMA Model Forecast",
       y = "Wholesale Trade",
       x = "Time") +
  theme_minimal()
```

The 95% prediction intervals for the ARIMA model are calculated with
$\hat{y}_{T+h|T} \pm 1.96\hat{\sigma}_h$ where $\hat{\sigma}_h^2$ is the
estimated forecast variance.



## NNAR

```{r, cache=TRUE}
forecasts_nnar <- NNAR_fit %>%
  forecast(h = "2 years")

#autoplot(forecasts_nnar) +
#  labs(title = "NNAR Model Forecast",
#       y = "Wholesale Trade",
#       x = "Time") +
#  theme_minimal()


autoplot(forecasts_nnar) +
  autolayer(full, series = "Actual Data") +
  labs(title = "NNAR Model Forecast with Actual Data",
       y = "Wholesale Trade",
       x = "Time") +
  theme_minimal()

hilo(forecasts_nnar, 95)
```

From the visual inspection, it appears that the ETS Model and ARIMA Model have better predictions. Next, the models will be further compared using performance metrics.


## Model comparison

```{r}
acc_ets = accuracy(forecasts, full)[c(".model", "MAE", "RMSE", "MAPE", "MASE")]
acc_arima = accuracy(arima_fc, full)[c(".model", "MAE", "RMSE", "MAPE", "MASE")]
acc_nnar = accuracy(forecasts_nnar, full)[c(".model", "MAE", "RMSE", "MAPE", "MASE")]

rbind(acc_ets, acc_arima, acc_nnar) %>% mutate(.model = c("ETS", "ARIMA", "NNAR"))
```

For all accuracy measures MAE, RMSE, MAPE, and MASE, the ETS model performed
the best, followed by ARIMA second and NNAR third.

# 7. Member contributions


Everyone completed the entire process for their model (from modeling to forecasting).
Eric: ARIMA models
Jinze Li: ETS models, Exploratory data analysis
Yucheng Wang, Tongxin Li: Neural network autoregression models







